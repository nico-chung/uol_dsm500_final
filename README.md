# Fixation Allocation to Semantic Regions in CAT2000: Persons, Faces, and Hands

This repository contains the Jupyter notebooks and associated manuscript for a final project in the MSc in Data Science and Artificial Intelligence program at Goldsmiths, University of London. The project investigates attentional allocation in visual scenes using the CAT2000 dataset, with a focus on semantic regions such as persons, faces, and hands. It employs a structured pipeline to process gaze fixation data, perform semantic segmentation, and conduct statistical hypothesis testing to evaluate preferences in attentional distribution.

The analysis pipeline integrates environment setup, exploratory data analysis, region-of-interest generation, semantic detection, segmentation with validation, and primary statistical testing. All processes are designed to be deterministic and reproducible, incorporating sensitivity analyses to ensure robustness against methodological artifacts.

## Project Overview

The core objective is to quantify how human observers allocate visual attention to socially relevant elements (persons, faces, and hands) in complex scenes. Key hypotheses tested include:
- A preference for persons over background elements (Cohort 1).
- A hierarchical preference for faces over hands (Cohort 2).

The workflow leverages tools such as density-based clustering (DBSCAN), vision-language models (e.g., Qwen2.5-VL for detection), and language-guided segmentation (Lang-SAM) with human-in-the-loop quality control. Statistical endpoints involve log density ratios, Wilcoxon signed-rank tests, and bootstrap confidence intervals.

## Repository Structure

The repository is organized as follows:
- **notebooks/**: Contains the Jupyter notebooks implementing the analysis pipeline.
  - `00_environment_setup.ipynb`: Establishes a reproducible environment, including manual asset placement (e.g., CAT2000 dataset, Qwen2.5-VL model), dependency installation via Conda and pip, and environment freezing for reproducibility.
  - `01_eda_and_qc.ipynb`: Performs exploratory data analysis (EDA) and quality control (QC) on the CAT2000 dataset, including file integrity checks, descriptive statistics on image dimensions and fixation maps, and preliminary tests for attentional differences between anthropomorphic and non-anthropomorphic scenes.
  - `02_roi_generation.ipynb`: Generates regions of interest (ROIs) from raw fixation data using DBSCAN clustering, followed by visual audits and statistical validation to create discrete attentional targets.
  - `03_semantic_detection.ipynb`: Detects semantic presence (humans, faces, hands) at the image level using a vision-language model with constrained grammar, producing flags for triage and segmentation task lists.
  - `04_segmentation_and_validation.ipynb`: Executes instance-level segmentation with Lang-SAM, applies manual QC to curate high-confidence cohorts, and constructs mutually exclusive class union masks for fixation assignment.
  - `05_allocation_analysis.ipynb`: Conducts primary statistical analysis and hypothesis testing on curated cohorts, including log density ratios, non-parametric tests, and sensitivity analyses (e.g., center-prior correction, boundary exclusion).
- **src/**: Contains supporting code, including `config.py` for project configurations (e.g., paths, constants like SEED=42, ALPHA=0.5, BETA=1e-6).
- **results/**: Output directory for artifacts generated by the notebooks (e.g., plots, Markdown tables, processed data).

## Requirements

To run the notebooks, ensure the following Python environment:
- Python 3.10+ (tested on 3.11 and 3.12).
- Key libraries (install via `pip` or Conda as guided in Notebook 00):
  ```
  pandas numpy matplotlib seaborn scipy pillow joblib shapely scikit-learn torch lang-sam tqdm
  ```
  Additional dependencies may include `statsmodels` for multiple testing corrections, `shapely` for geometric operations, and others listed in the frozen environment files (`pip_freeze.txt`, `conda_list_explicit.txt`).

The notebooks assume access to the CAT2000 dataset (stimulus images and fixation .mat files), which should be manually placed as described in Notebook 00. For semantic detection and segmentation, a locally hosted vision-language model (e.g., Qwen2.5-VL GGUF files) and Lang-SAM are required; refer to Notebooks 00, 03, and 04 for setup details.

## Usage

1. Clone the repository:
   ```
   git clone https://github.com/your-username/repo-name.git
   cd repo-name
   ```

2. Configure paths in `src/config.py` (e.g., dataset location, results directory).

3. Run Notebook 00 to set up the environment:
   - This installs dependencies and freezes the setup. Manual asset placement (e.g., downloading CAT2000 and Qwen2.5-VL) is required first, as detailed in the notebook.
   ```
   jupyter notebook notebooks/00_environment_setup.ipynb
   ```

4. Proceed to run the remaining notebooks sequentially:
   ```
   jupyter notebook
   ```
   Start with `01_eda_and_qc.ipynb` and proceed to `05_allocation_analysis.ipynb`. Each notebook is self-contained but builds on prior outputs for reproducibility.

Note: Some steps (e.g., segmentation in Notebook 04) are long-running and idempotent, allowing resumption from interruptions.

## Reproducibility

All random processes use a fixed seed (SEED=42) for determinism. Outputs are stored in `results/`, organized by notebook and section. The pipeline emphasizes auditability, with visual inspections and Markdown exports for key results. Environment freezing in Notebook 00 ensures the setup can be recreated exactly.

## License

This project is licensed under the MIT License. 